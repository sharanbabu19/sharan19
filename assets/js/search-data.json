{
  
    
        "post0": {
            "title": "Title",
            "content": "GANs use two networks competing against each other to generate data. . 1) Generator : Recieves random noise (Gaussian Distribution). Outputs data (often an image) . 2) Discriminator: Takes a data set consisting of real images from the real data set and fake images from the generator Attempt to classify real vs fake images (always binary classification) . import numpy as np import pandas as pd import matplotlib.pyplot as plt . from tensorflow.keras.datasets import mnist . (X_train,y_train), (X_test, y_test) = mnist.load_data() . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 11493376/11490434 [==============================] - 2s 0us/step . plt.imshow(X_train[0]) . &lt;matplotlib.image.AxesImage at 0x204969adcf8&gt; . y_train . array([5, 0, 4, ..., 5, 6, 8], dtype=uint8) . only_zeros = X_train[y_train==0] . print(X_train.shape, only_zeros.shape) . (60000, 28, 28) (5923, 28, 28) . plt.imshow(only_zeros[19]) . &lt;matplotlib.image.AxesImage at 0x20496faab70&gt; . import tensorflow as tf from tensorflow.keras.layers import Dense,Reshape,Flatten from tensorflow.keras.models import Sequential . discriminator = Sequential() discriminator.add(Flatten(input_shape=[28,28])) discriminator.add(Dense(150,activation=&#39;relu&#39;)) discriminator.add(Dense(100,activation=&#39;relu&#39;)) # Final output layer discriminator.add(Dense(1,activation=&#39;sigmoid&#39;)) discriminator.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;) . discriminator.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 _________________________________________________________________ dense (Dense) (None, 150) 117750 _________________________________________________________________ dense_1 (Dense) (None, 100) 15100 _________________________________________________________________ dense_2 (Dense) (None, 1) 101 ================================================================= Total params: 132,951 Trainable params: 132,951 Non-trainable params: 0 _________________________________________________________________ . codings_size = 100 generator = Sequential() generator.add(Dense(100,activation=&#39;relu&#39;,input_shape=[codings_size])) generator.add(Dense(150,activation=&#39;relu&#39;)) generator.add(Dense(784,activation=&#39;relu&#39;)) # Discriminator expects shape of 28x28 generator.add(Reshape([28,28])) # We do not compile the generator GAN = Sequential([generator,discriminator]) . generator.summary() . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_3 (Dense) (None, 100) 10100 _________________________________________________________________ dense_4 (Dense) (None, 150) 15150 _________________________________________________________________ dense_5 (Dense) (None, 784) 118384 _________________________________________________________________ reshape (Reshape) (None, 28, 28) 0 ================================================================= Total params: 143,634 Trainable params: 143,634 Non-trainable params: 0 _________________________________________________________________ . GAN.summary() . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= sequential_1 (Sequential) (None, 28, 28) 143634 _________________________________________________________________ sequential (Sequential) (None, 1) 132951 ================================================================= Total params: 276,585 Trainable params: 143,634 Non-trainable params: 132,951 _________________________________________________________________ . GAN.layers . [&lt;tensorflow.python.keras.engine.sequential.Sequential at 0x204990c9f98&gt;, &lt;tensorflow.python.keras.engine.sequential.Sequential at 0x20483bcf6a0&gt;] . GAN.layers[1].summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 _________________________________________________________________ dense (Dense) (None, 150) 117750 _________________________________________________________________ dense_1 (Dense) (None, 100) 15100 _________________________________________________________________ dense_2 (Dense) (None, 1) 101 ================================================================= WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ? Total params: 265,902 Trainable params: 132,951 Non-trainable params: 132,951 _________________________________________________________________ . discriminator.trainable = False # Shouldn&#39;t be trained in the second phase . GAN.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;) . batch_size = 32 my_data = only_zeros . dataset = tf.data.Dataset.from_tensor_slices(my_data).shuffle(buffer_size=1000) . type(dataset) . tensorflow.python.data.ops.dataset_ops.ShuffleDataset . dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1) . epochs = 1 . noise = tf.random.normal(shape=[batch_size,codings_size]) noise . &lt;tf.Tensor: shape=(32, 100), dtype=float32, numpy= array([[-0.17894243, 0.28046852, -1.2658674 , ..., -1.8558825 , 0.49134666, -0.02820994], [-0.57840776, 1.028697 , 1.0578247 , ..., 1.2367849 , -1.26806 , -0.07681153], [ 1.2107298 , 1.1793936 , -0.17294073, ..., 1.1151178 , 0.6852811 , 1.0923375 ], ..., [-0.23432946, -1.8061259 , 0.12568073, ..., 0.70886606, -0.14349754, -0.61847156], [-1.3304747 , -1.5051615 , -0.9862153 , ..., 1.2475176 , -1.0224384 , 0.431593 ], [-0.12189417, 0.76724905, 0.23410986, ..., -1.2387109 , 1.165128 , -2.2503793 ]], dtype=float32)&gt; . generator(noise) . &lt;tf.Tensor: shape=(32, 28, 28), dtype=float32, numpy= array([[[1.39178470e-01, 0.00000000e+00, 1.32437050e-01, ..., 0.00000000e+00, 1.24021992e-01, 6.28608763e-02], [6.59890613e-03, 2.57760793e-01, 0.00000000e+00, ..., 1.15738064e-01, 2.14011580e-01, 5.65851629e-02], [0.00000000e+00, 0.00000000e+00, 1.05919935e-01, ..., 0.00000000e+00, 0.00000000e+00, 1.68934196e-01], ..., [0.00000000e+00, 0.00000000e+00, 1.86894268e-01, ..., 0.00000000e+00, 0.00000000e+00, 2.71052748e-01], [2.84300804e-01, 0.00000000e+00, 0.00000000e+00, ..., 2.44469017e-01, 1.92485914e-01, 9.82135981e-02], [1.36533707e-01, 1.01417536e-02, 2.23434702e-01, ..., 2.80212998e-01, 0.00000000e+00, 1.18388772e-01]], [[1.01866886e-01, 8.40153452e-03, 3.36099118e-01, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [1.97205901e-01, 3.08540463e-01, 0.00000000e+00, ..., 0.00000000e+00, 6.23972267e-02, 0.00000000e+00], [0.00000000e+00, 9.11480337e-02, 0.00000000e+00, ..., 0.00000000e+00, 0.00000000e+00, 1.46415949e-01], ..., [0.00000000e+00, 0.00000000e+00, 3.23097338e-03, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [2.26200327e-01, 0.00000000e+00, 0.00000000e+00, ..., 0.00000000e+00, 1.98774487e-01, 0.00000000e+00], [8.80293269e-03, 1.53370097e-01, 0.00000000e+00, ..., 2.82919168e-01, 0.00000000e+00, 0.00000000e+00]], [[1.17725708e-01, 2.23612323e-01, 1.17519675e-02, ..., 0.00000000e+00, 3.49459708e-01, 7.10227117e-02], [9.54425707e-02, 2.67689358e-02, 0.00000000e+00, ..., 0.00000000e+00, 1.77097246e-01, 0.00000000e+00], [1.30967632e-01, 1.29050925e-01, 6.73688576e-02, ..., 1.02557778e-01, 0.00000000e+00, 1.15729682e-01], ..., [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ..., 0.00000000e+00, 0.00000000e+00, 2.39297479e-01], [3.21245670e-01, 0.00000000e+00, 1.83343470e-01, ..., 3.25962126e-01, 1.40042186e-01, 0.00000000e+00], [1.80492461e-01, 3.51804972e-01, 2.36293271e-01, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], ..., [[1.42159536e-01, 0.00000000e+00, 0.00000000e+00, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [0.00000000e+00, 4.44585770e-01, 0.00000000e+00, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [2.04186380e-01, 0.00000000e+00, 6.70287386e-02, ..., 0.00000000e+00, 0.00000000e+00, 3.81664932e-01], ..., [0.00000000e+00, 1.49426967e-01, 1.63367286e-01, ..., 2.98328828e-02, 0.00000000e+00, 0.00000000e+00], [1.97943553e-01, 0.00000000e+00, 2.27516845e-01, ..., 4.64169234e-02, 1.18896528e-03, 0.00000000e+00], [2.69571096e-01, 2.77383655e-01, 4.21722472e-01, ..., 1.52053118e-01, 6.74408153e-02, 0.00000000e+00]], [[6.14769608e-02, 2.81049967e-01, 0.00000000e+00, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [2.63842016e-01, 0.00000000e+00, 0.00000000e+00, ..., 0.00000000e+00, 2.18015909e-02, 0.00000000e+00], [7.67226219e-02, 3.32821041e-01, 0.00000000e+00, ..., 5.93183376e-02, 0.00000000e+00, 4.10942137e-01], ..., [0.00000000e+00, 9.55804810e-03, 4.89544719e-02, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [2.31722251e-01, 0.00000000e+00, 1.59873813e-01, ..., 0.00000000e+00, 7.27455840e-02, 9.92300510e-02], [2.08125293e-01, 0.00000000e+00, 6.86223879e-02, ..., 0.00000000e+00, 1.10909343e-04, 0.00000000e+00]], [[4.18031871e-01, 5.28196394e-02, 4.48989421e-02, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [2.00054914e-01, 1.48861587e-01, 0.00000000e+00, ..., 0.00000000e+00, 2.44434997e-02, 0.00000000e+00], [0.00000000e+00, 6.79483935e-02, 1.54806316e-01, ..., 0.00000000e+00, 0.00000000e+00, 1.94236770e-01], ..., [0.00000000e+00, 0.00000000e+00, 5.45343012e-02, ..., 0.00000000e+00, 0.00000000e+00, 1.19087696e-02], [9.12818313e-02, 0.00000000e+00, 4.18430388e-01, ..., 3.52661490e-01, 3.92701089e-01, 0.00000000e+00], [1.65195346e-01, 1.91727772e-01, 1.21707544e-01, ..., 7.65198320e-02, 5.71975708e-02, 0.00000000e+00]]], dtype=float32)&gt; . generator, discriminator = GAN.layers for epoch in range(10): # 10 is number of epochs print(f&quot;Currently on Epoch {epoch+1}&quot;) i = 0 for X_batch in dataset: i = i+1 if i%100 == 0: print(f&quot; t Currently on batch number {i} of {len(my_data)//batch_size}&quot;) # DISCRIMINATOR TRAINING PHASE noise = tf.random.normal(shape=[batch_size,codings_size]) # GENERATOR gets to see only this random noise gen_images = generator(noise) X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch,tf.float32)],axis=0) y1 = tf.constant([[0.0]]*batch_size + [[1.0]]*batch_size) # 0 correspond to not real and vice-versa discriminator.trainable = True discriminator.train_on_batch(X_fake_vs_real,y1) # TRAIN GENERATOR noise = tf.random.normal(shape=[batch_size,codings_size]) y2 = tf.constant([[1.0]]*batch_size) discriminator.trainable = False GAN.train_on_batch(noise,y2) print(&quot;Training complete!&quot;) . Currently on Epoch 1 Currently on batch number 100 of 185 Currently on Epoch 2 Currently on batch number 100 of 185 Currently on Epoch 3 Currently on batch number 100 of 185 Currently on Epoch 4 Currently on batch number 100 of 185 Currently on Epoch 5 Currently on batch number 100 of 185 Currently on Epoch 6 Currently on batch number 100 of 185 Currently on Epoch 7 Currently on batch number 100 of 185 Currently on Epoch 8 Currently on batch number 100 of 185 Currently on Epoch 9 Currently on batch number 100 of 185 Currently on Epoch 10 Currently on batch number 100 of 185 Training complete! . noise = tf.random.normal(shape=[10, codings_size]) noise.shape . TensorShape([10, 100]) . plt.imshow(noise) . &lt;matplotlib.image.AxesImage at 0x2049b9b6080&gt; . image = generator(noise) image.shape . TensorShape([10, 28, 28]) . plt.imshow(image[5]) . &lt;matplotlib.image.AxesImage at 0x2049ba875c0&gt; . plt.imshow(image[1]) # Hence, model has undergone &#39;mode collapse&#39;. . &lt;matplotlib.image.AxesImage at 0x2049bae7a58&gt; . X_train = X_train/255 X_train = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # Because we will be using &#39;tanh&#39; later . X_train.min() . -1.0 . X_train.max() . 1.0 . only_zeros = X_train[y_train==0] . only_zeros.shape . (5923, 28, 28, 1) . import tensorflow as tf from tensorflow.keras.layers import Dense,Reshape,Dropout,LeakyReLU,Flatten,BatchNormalization,Conv2D,Conv2DTranspose from tensorflow.keras.models import Sequential . np.random.seed(42) tf.random.set_seed(42) codings_size = 100 . generator = Sequential() generator.add(Dense(7 * 7 * 128, input_shape=[codings_size])) generator.add(Reshape([7, 7, 128])) generator.add(BatchNormalization()) generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding=&quot;same&quot;, activation=&quot;relu&quot;)) generator.add(BatchNormalization()) generator.add(Conv2DTranspose(1, kernel_size=5, strides=2, padding=&quot;same&quot;, activation=&quot;tanh&quot;)) . discriminator = Sequential() discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding=&quot;same&quot;, activation=LeakyReLU(0.3), input_shape=[28, 28, 1])) discriminator.add(Dropout(0.5)) discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=&quot;same&quot;, activation=LeakyReLU(0.3))) discriminator.add(Dropout(0.5)) discriminator.add(Flatten()) discriminator.add(Dense(1, activation=&quot;sigmoid&quot;)) . GAN = Sequential([generator, discriminator]) . discriminator.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;adam&quot;) discriminator.trainable = False . GAN.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;adam&quot;) . GAN.layers . [&lt;tensorflow.python.keras.engine.sequential.Sequential at 0x2049bacf240&gt;, &lt;tensorflow.python.keras.engine.sequential.Sequential at 0x2049bb33fd0&gt;] . GAN.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= sequential_3 (Sequential) (None, 28, 28, 1) 840705 _________________________________________________________________ sequential_4 (Sequential) (None, 1) 212865 ================================================================= Total params: 1,053,570 Trainable params: 840,321 Non-trainable params: 213,249 _________________________________________________________________ . GAN.layers[0].summary() . Model: &#34;sequential_3&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_6 (Dense) (None, 6272) 633472 _________________________________________________________________ reshape_1 (Reshape) (None, 7, 7, 128) 0 _________________________________________________________________ batch_normalization (BatchNo (None, 7, 7, 128) 512 _________________________________________________________________ conv2d_transpose (Conv2DTran (None, 14, 14, 64) 204864 _________________________________________________________________ batch_normalization_1 (Batch (None, 14, 14, 64) 256 _________________________________________________________________ conv2d_transpose_1 (Conv2DTr (None, 28, 28, 1) 1601 ================================================================= Total params: 840,705 Trainable params: 840,321 Non-trainable params: 384 _________________________________________________________________ . batch_size = 32 my_data = only_zeros dataset = tf.data.Dataset.from_tensor_slices(my_data).shuffle(buffer_size=1000) type(dataset) . tensorflow.python.data.ops.dataset_ops.ShuffleDataset . dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1) epochs = 20 . generator, discriminator = GAN.layers # For every epcoh for epoch in range(epochs): print(f&quot;Currently on Epoch {epoch+1}&quot;) i = 0 # For every batch in the dataset for X_batch in dataset: i=i+1 if i%20 == 0: print(f&quot; tCurrently on batch number {i} of {len(my_data)//batch_size}&quot;) ##################################### ## TRAINING THE DISCRIMINATOR ###### ################################### # Create Noise noise = tf.random.normal(shape=[batch_size, codings_size]) # Generate numbers based just on noise input gen_images = generator(noise) # Concatenate Generated Images against the Real Ones # TO use tf.concat, the data types must match! X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch,tf.float32)], axis=0) # Targets set to zero for fake images and 1 for real images y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size) # This gets rid of a Keras warning discriminator.trainable = True # Train the discriminator on this batch discriminator.train_on_batch(X_fake_vs_real, y1) ##################################### ## TRAINING THE GENERATOR ###### ################################### # Create some noise noise = tf.random.normal(shape=[batch_size, codings_size]) # We want discriminator to belive that fake images are real y2 = tf.constant([[1.]] * batch_size) # Avois a warning discriminator.trainable = False GAN.train_on_batch(noise, y2) print(&quot;TRAINING COMPLETE&quot;) . Currently on Epoch 1 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 2 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 3 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 4 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 5 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 6 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 7 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 8 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 9 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 10 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 11 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 12 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 13 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 14 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 15 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 16 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 17 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 18 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 19 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 Currently on Epoch 20 Currently on batch number 20 of 185 Currently on batch number 40 of 185 Currently on batch number 60 of 185 Currently on batch number 80 of 185 Currently on batch number 100 of 185 Currently on batch number 120 of 185 Currently on batch number 140 of 185 Currently on batch number 160 of 185 Currently on batch number 180 of 185 TRAINING COMPLETE . noise = tf.random.normal(shape=[10, codings_size]) noise.shape . TensorShape([10, 100]) . plt.imshow(noise) . &lt;matplotlib.image.AxesImage at 0x2049c9315f8&gt; . images = generator(noise) . single_image = images[0] . for image in images: plt.imshow(image.numpy().reshape(28,28)) plt.show() . plt.imshow(single_image.numpy().reshape(28,28)) . &lt;matplotlib.image.AxesImage at 0x204a1c3acc0&gt; .",
            "url": "https://sharanbabu19.github.io/sharan19/2020/10/01/Generative-Adversarial-Networks.html",
            "relUrl": "/2020/10/01/Generative-Adversarial-Networks.html",
            "date": " ‚Ä¢ Oct 1, 2020"
        }
        
    
  
    
  
    
        ,"post2": {
            "title": "Flattening Nested Lists In Python",
            "content": "list_of_lists = [[1], [2, 3], [4, 5, 6]] sum(list_of_lists, []) ==&gt; [1, 2, 3, 4, 5, 6] .",
            "url": "https://sharanbabu19.github.io/sharan19/2020/09/24/Flattening-nested-lists-in-Python.html",
            "relUrl": "/2020/09/24/Flattening-nested-lists-in-Python.html",
            "date": " ‚Ä¢ Sep 24, 2020"
        }
        
    
  
    
  
    
        ,"post4": {
            "title": "SweetViz",
            "content": "## Package is a collection of modules. ## Library is a collection of Packages. . Hi there. Today, we are going to see how to use SweetViz library in Python which will enable us to perform powerful Exploratory Data Analysis(EDA) on your dataset. So,let&#39;s get started. . First, you will have to pip install this package as it is not an in-built Python package. You can do so from the command prompt or using !pip install sweetviz from jupyter notebook environment. . I will be using USA Housing data in this example. . !pip install sweetviz . Collecting sweetviz Downloading https://files.pythonhosted.org/packages/8f/bd/f4454adfe1d3bbd04892d6172348ca215fa62d59fb09c1ac6b8a233341d3/sweetviz-1.0a7-py3-none-any.whl (323kB) Requirement already satisfied: scipy&gt;=1.3.2 in c: users sharan babu anaconda3 lib site-packages (from sweetviz) (1.4.1) Collecting tqdm&gt;=4.43.0 (from sweetviz) Downloading https://files.pythonhosted.org/packages/f3/76/4697ce203a3d42b2ead61127b35e5fcc26bba9a35c03b32a2bd342a4c869/tqdm-4.46.1-py2.py3-none-any.whl (63kB) Collecting pandas!=1.0.0,!=1.0.1,!=1.0.2,&gt;=0.25.3 (from sweetviz) Downloading https://files.pythonhosted.org/packages/1d/eb/b4f68f54ad287d583c9c3b3c77f865615f832f092810f20d2b44498cd06c/pandas-1.0.4-cp37-cp37m-win_amd64.whl (8.7MB) Collecting matplotlib&gt;=3.1.3 (from sweetviz) Downloading https://files.pythonhosted.org/packages/b4/4d/8a2c06cb69935bb762738a8b9d5f8ce2a66be5a1410787839b71e146f000/matplotlib-3.2.1-cp37-cp37m-win_amd64.whl (9.2MB) Collecting importlib-resources&gt;=1.2.0 (from sweetviz) Downloading https://files.pythonhosted.org/packages/b6/03/1865fdd49ec9a938f9f84b255d3d37863df9fbd18b48c1c3f761040cbf13/importlib_resources-2.0.0-py2.py3-none-any.whl Collecting jinja2&gt;=2.11.1 (from sweetviz) Downloading https://files.pythonhosted.org/packages/30/9e/f663a2aa66a09d838042ae1a2c5659828bb9b41ea3a6efa20a20fd92b121/Jinja2-2.11.2-py2.py3-none-any.whl (125kB) Requirement already satisfied: numpy&gt;=1.16.0 in c: users sharan babu anaconda3 lib site-packages (from sweetviz) (1.16.4) Requirement already satisfied: pytz&gt;=2017.2 in c: users sharan babu anaconda3 lib site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,&gt;=0.25.3-&gt;sweetviz) (2019.1) Requirement already satisfied: python-dateutil&gt;=2.6.1 in c: users sharan babu anaconda3 lib site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,&gt;=0.25.3-&gt;sweetviz) (2.8.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in c: users sharan babu anaconda3 lib site-packages (from matplotlib&gt;=3.1.3-&gt;sweetviz) (1.1.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in c: users sharan babu anaconda3 lib site-packages (from matplotlib&gt;=3.1.3-&gt;sweetviz) (2.4.0) Requirement already satisfied: cycler&gt;=0.10 in c: users sharan babu anaconda3 lib site-packages (from matplotlib&gt;=3.1.3-&gt;sweetviz) (0.10.0) Requirement already satisfied: zipp&gt;=0.4; python_version &lt; &#34;3.8&#34; in c: users sharan babu anaconda3 lib site-packages (from importlib-resources&gt;=1.2.0-&gt;sweetviz) (0.5.1) Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in c: users sharan babu anaconda3 lib site-packages (from importlib-resources&gt;=1.2.0-&gt;sweetviz) (0.17) Requirement already satisfied: MarkupSafe&gt;=0.23 in c: users sharan babu anaconda3 lib site-packages (from jinja2&gt;=2.11.1-&gt;sweetviz) (1.1.1) Requirement already satisfied: six&gt;=1.5 in c: users sharan babu anaconda3 lib site-packages (from python-dateutil&gt;=2.6.1-&gt;pandas!=1.0.0,!=1.0.1,!=1.0.2,&gt;=0.25.3-&gt;sweetviz) (1.12.0) Requirement already satisfied: setuptools in c: users sharan babu anaconda3 lib site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib&gt;=3.1.3-&gt;sweetviz) (41.0.1) Installing collected packages: tqdm, pandas, matplotlib, importlib-resources, jinja2, sweetviz Found existing installation: tqdm 4.32.1 Uninstalling tqdm-4.32.1: Successfully uninstalled tqdm-4.32.1 Found existing installation: pandas 0.24.2 Uninstalling pandas-0.24.2: Successfully uninstalled pandas-0.24.2 Found existing installation: matplotlib 3.1.0 Uninstalling matplotlib-3.1.0: Successfully uninstalled matplotlib-3.1.0 Found existing installation: Jinja2 2.10.1 Uninstalling Jinja2-2.10.1: Successfully uninstalled Jinja2-2.10.1 Successfully installed importlib-resources-2.0.0 jinja2-2.11.2 matplotlib-3.2.1 pandas-1.0.4 sweetviz-1.0a7 tqdm-4.46.1 . import numpy as np import pandas as pd import sweetviz . df = pd.read_csv(r&quot;C: Users Sharan Babu Desktop Data science original Refactored_Py_DS_ML_Bootcamp-master 11-Linear-Regression USA_housing.csv&quot;) . df.head() # In this dataset, price column is the target feature or dependent variable. . Avg. Area Income Avg. Area House Age Avg. Area Number of Rooms Avg. Area Number of Bedrooms Area Population Price Address . 0 79545.458574 | 5.682861 | 7.009188 | 4.09 | 23086.800503 | 1.059034e+06 | 208 Michael Ferry Apt. 674 nLaurabury, NE 3701... | . 1 79248.642455 | 6.002900 | 6.730821 | 3.09 | 40173.072174 | 1.505891e+06 | 188 Johnson Views Suite 079 nLake Kathleen, CA... | . 2 61287.067179 | 5.865890 | 8.512727 | 5.13 | 36882.159400 | 1.058988e+06 | 9127 Elizabeth Stravenue nDanieltown, WI 06482... | . 3 63345.240046 | 7.188236 | 5.586729 | 3.26 | 34310.242831 | 1.260617e+06 | USS Barnett nFPO AP 44820 | . 4 59982.197226 | 5.040555 | 7.839388 | 4.23 | 26354.109472 | 6.309435e+05 | USNS Raymond nFPO AE 09386 | . Analyzing a DataFrame . analysis = sweetviz.analyze([df,&quot;EDA&quot;], target_feat=&#39;Price&#39;) . :FEATURES DONE: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [100%] 00:06 -&gt; (00:00 left) :PAIRWISE DONE: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [100%] 00:00 -&gt; (00:00 left) . Creating Associations graph... DONE! . type(analysis) . sweetviz.dataframe_report.DataframeReport . analysis.show_html(&#39;EDA.html&#39;) . This is an amazing visualization library for your data as you instantly get various insights into your data which you could have done manually but would have taken a lot more time. For numerical features, you get point plot, histogram, number of value missing, number of distinct values, quartile values and more useful information like skewness of the column. For categorical features, along with the number of distinct and missing values, you Additionally, you also get the the &#39;Associations&#39; or pair-wise correlations between 2 variables which is helpful for determining feature importance. . You can also use this library to comapre two DataFrames,say, your Training set and Test set and infer some meaning from the comparison. . train = df[:3000] . test = df[3000:] . # Consider &#39;test&#39; to be the Test data. # The command to perform EDA comparison is: analysis = sweetviz.compare([train,&quot;Train&quot;],[test,&quot;Test&quot;], &quot;Price&quot;) # Price is the target variable common to both tables # Now you can view your results. analysis.show_html(&#39;EDA2.html&#39;) . :FEATURES DONE: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [100%] 00:08 -&gt; (00:00 left) :PAIRWISE DONE: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [100%] 00:00 -&gt; (00:00 left) . Creating Associations graph... DONE! . Now, you can see comparison between the Train and Test dataset differentiate by different colors for all paramters discussed above. Therefore, this is a handy module .",
            "url": "https://sharanbabu19.github.io/sharan19/2020/09/19/SweetViz-Automated-EDA.html",
            "relUrl": "/2020/09/19/SweetViz-Automated-EDA.html",
            "date": " ‚Ä¢ Sep 19, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi there, I am Sharan üëã . I am an aspiring Data Scientist pursuing an undergraduate degree in Computer Science. . ‚ö° Curiously exploring the depths of Deep Learning and SOTA models. | :man_technologist: I‚Äôm currently working on DeHazing Images. | üå± Currently learning Deep Learning. | :smile: Looking to collaborate on ML/Data Science Projects. | üí¨ Let‚Äôs talk about Hackathons, Machine Learning or Computer Vision. | :mailbox_with_mail: Email: sharanbabu2001@gmail.com | . Know more: . Github | LinkedIn | Portfolio | Medium | Resume | Youtube .",
          "url": "https://sharanbabu19.github.io/sharan19/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://sharanbabu19.github.io/sharan19/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}